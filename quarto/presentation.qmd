---
title: "ğŸ· Ã€ boire ğŸ»"
subtitle: "*Le breuvage contre-attaque*"
author: "`Guillaume DEVANT` & `Corentin DUCLOUX`"
format: 
    revealjs:
        theme: [serif, custom.scss]
        background-transition: fade
        transition: slide
        navigation-mode: linear
        footer: "**Machine Learning**"
        logo: https://corentinducloux.fr/dossier_img/mecen_transparent.png
---


## Introduction {background-image="img\territoire_vin.png" background-opacity="0.5"}

<link rel="stylesheet" 
href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

<link href='https://fonts.googleapis.com/css?family=Fira Code' rel='stylesheet'>


- Une immersion en territoire alcoolisÃ© s'impose...
<div style="display: flex; justify-content: center; align-items: center; height: 60vh;">
<iframe width="800" height="340" src="https://www.youtube.com/embed/mZ6xNxpuIOQ" title="Bodh&#39;Aktan - Ã€ boire" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div>

## Le *Pourquoi* du *Comment* {background-image="img\bouteille_dieu.png" background-opacity="0.5"}

- Le 18 janvier approche, une date en apparence anodine mais trÃ¨s importante pour nos deux compÃ¨res.
- Pour cette journÃ©e festive, nos 2 protagonistes se rendirent sur `vinatis.com` pour trouver un breuvage.
- Et c'est Ã  ce moment que l'histoire prend **racine**...

::: {.fragment}
::: {.fragment .grow}
![](img\racine.jpg){fig-align="center" height="120"}
:::
::: {.fragment}
**On parle de moi ?**
:::
:::

::: {.notes}
- Nous avons commencÃ© Ã  rechercher notre proie dÃ¨s fin septembre pour faire quelques tests, notamment sur la partie scraping.
:::

## Scraping {background-image="img\bouteille_scrap.png" background-opacity="0.5"}

> *â€œPour savoir qu'un verre Ã©tait de trop, encore faut-il avoir scrapÃ© son vin !â€* $-$ **Inconnu**

::: {.notes}
Eh non Jean ! On ne parle pas de toi mais bien du scraping de vin. D'ailleurs on voit au tableau ce magnifique proverbe indonÃ©so-inconnu qui Ã©nonce que **Pour savoir qu'un verre Ã©tait de trop, encore faut-il avoir scrapÃ© son vin !**

Ca t'a ouvert les chakras Guillaume ? Ouais, non ? Bon moi non plus, et si on passait Ã  la partie technique plutÃ´t ?
:::

## Scraping, Partie I {.smaller}

`scraping_functions.py` $\Rightarrow$ Le coeur du scraper

1. Construit des URL avec *query parameters* en utilisant le package `yarl`.

```python
URL_INIT = URL.build(scheme="https", host="vinatis.com")
WHITE = "achat-vin-blanc"
RED = "achat-vin-rouge"
ROSE = "achat-vin-rose"

>>> URL_INIT / WHITE % {"page": 1, "tri": 7}
... URL('https://vinatis.com/achat-vin-blanc?page=1&tri=7')
```

2. `create_session` crÃ©e une session HTML avec un User-Agent et un Proxy alÃ©atoire, pouvant changer entre les requÃªtes.
3. PossÃ¨de un dÃ©corateur `@random_waiter(min, max)` permettant de gÃ©nÃ©rer un temps d'attente alÃ©atoire entre les deux bornes spÃ©cifiÃ©es entre chaque requÃªte **GET** pour Ã©viter d'envoyer trop de requÃªtes dans un laps de temps rÃ©duit.
4. `create_all_wine_urls` permet de crÃ©er l'ensemble des liens **href**.
5. `export_wine_links` permet d'exporter ces liens dans un fichier CSV.

::: {.notes}
Pour un peu de mise en contexte, initialement on avait commencÃ© par scraper les pages de vente de vins oÃ¹ une trentaine de vins sont affichÃ©s...mais on s'est rapidement rendu compte que dans ces pages, il manquait beaucoup d'informations. On s'est plutÃ´t mis en tÃªte de rÃ©cupÃ©rer les caractÃ©ristiques sur chaque page individuelle de vin, qu'on peut facilement rÃ©cupÃ©rer sur les pages de recherche grÃ¢ce Ã  des liens href. Et initialement, on l'avait fait avec `Selenium` mais Ã§a prenait un temps monstre donc on a changÃ© d'idÃ©e.

*Note* : On aurait pu construire les URL Ã  la main mais c'Ã©tait beaucoup moins Ã©lÃ©gant que de le faire comme Ã§a.

- Ensuite on a voulu introduire un User Agent rÃ©aliste quand on effectue notre requÃªte get, pour Ã©viter que le site ne finisse par comprendre que c'est un bot. Ca permet simplement d'envoyer des en-tÃªtes que renvoierai un navigateur comme Firefox, Chrome ou Edge. 
- Le proxy permet quant Ã  lui de masquer son adresse IP, au cas oÃ¹ on finirait par se faire bannir.
- On a aussi voulu Ã©viter de surcharger les serveurs en envoyant trop de requÃªtes en mÃªme temps donc on a utilisÃ© un dÃ©corateur (**point 3**)

Cela Ã©tant, on a eu aucun problÃ¨me jusqu'ici chaque fois qu'on a fait le scraping. 
:::

## Scraping, Partie II {.smaller}

1. On va ensuite requÃªter ces liens **href** avec `create_json` et rÃ©cupÃ©rer les pages brutes en HTML.
2. La fonction `scraping` du module `mystical_soup` va permettre d'extraire toutes les informations intÃ©ressantes de la page brute et renvoyer la dataclass `Vin` sÃ©rialisable en *JSON*.

<i class="fa-solid fa-wine-bottle"></i> *Exemple* d'un `Vin` et ses caractÃ©ristiques sÃ©rialisÃ©s en *JSON* :

```json
{
        "name": "PINOT NOIR 2019 LAS PIZARRAS - ERRAZURIZ",
        "capacity": "0,75 L",
        "price": "94,90 â‚¬",
        "price_bundle": null,
        "characteristics": "Vin Rouge / Chili / Central Valley / Aconcagua Valley DO / 13,5 % vol / 100% Pinot noir",
        "note": null,
        "keywords": [
            "ElÃ©gance",
            "Finesse",
            "Harmonie"
        ],
        "others": null,
        "picture": "https://www.vinatis.com/67234-detail_default/pinot-noir-2019-las-pizarras-errazuriz.png",
        "classification": null,
        "millesime": "2019",
        "cepage": "100% Pinot noir",
        "gouts": "Rouge Charnu et fruitÃ©",
        "par_gouts": "Puissant",
        "oeil": "Robe rubis aux reflets violets.",
        "nez": "Nez complexe sur la griotte, les Ã©pices et les champignons (truffe).",
        "bouche": "Bouche fruitÃ©e et florale. Tanins structurÃ©s, Ã©lÃ©gants et fins. finale harmonieuse et persistante.",
        "temperature": "8-10Â°C",
        "service": "En bouteille ou en carafe",
        "conservation_1": "2026",
        "conservation_2": "A boire et Ã  garder",
        "accords_vins": "ApÃ©ritif, EntrÃ©e, Charcuterie, Viande rouge, Viande blanche, Volaille, Gibier, Champignon, Barbecue, Cuisine du monde, Fromage, Dessert fruitÃ©, Dessert chocolatÃ©",
        "accords_reco": "Gigot d'agneau aux herbes de Provence; Tikka massala; Plateau de fromages."
    }
```

::: {.notes}

Une fois que l'on a rÃ©cupÃ©rÃ© tous les URLs des pages des vins, on va scraper chaque page avec le module `mystical_soup`. Toutes les informations qui nous intÃ©resse sont stockÃ© dans un fichier JSON.

:::

## ğŸ§¹ Cleaning {.smaller background-image="img\pandas_vs_polars.png" background-opacity="0.25"}

Mais ce *JSON* **brut** doit Ãªtre nettoyÃ© et considÃ©rablement restructurÃ© !

1. Nous avons choisi d'utiliser `polars` ğŸ» et non pas `pandas` ğŸ¼ pour le faire.
2. Toutes les fonctions de nettoyage sont contenues dans `bear_cleaner.py`.
3. La fonction `super_pipe` permet de chainer toutes les transformations dans un pipeline propre pour structurer notre **Dataframe**.
4. Nous obtenons ainsi un **Dataframe** de taille `(4006,40)` prÃªt pour le Machine Learning 

![](img\bear_data.png){fig-align="center"}

::: {.notes}
On l'a vu avec l'exemple d'un vin sÃ©rialisÃ© en json sur la slide prÃ©cÃ©dente, les entrÃ©es ne sont pas nettoyÃ©es : les valeurs numÃ©riques sont stockÃ©es sous forme de texte, etc.

**Pourquoi polars ?** $\Rightarrow$ Les expressions polars nous permettent de faire tout un tas d'opÃ©rations sans jamais utiliser des lambda functions, l'API est mieux documentÃ©e.

- En sortie : 4006 vins distincts et 40 variables !
:::

## Machine Learning {background-image="img\bouteille_ecole.png" background-opacity="0.25"}

> *â€œ2024 sera un millÃ©sime franÃ§ais !â€* $-$ **Emmanuel Macron**

## Machine Learning - ProcÃ©dure {.smaller background-image="img\pipeline.png" background-opacity="0.25"}

1. Deux variables Ã  prÃ©dire : *unit_price* & *type*
2. Utilisation de 6 modÃ¨les de **Machine Learning**
3. â¶ Optimisation des hyperparamÃ¨tres $\Rightarrow$ `models.py`
4. ğŸ¹ PrÃ©diction sur les donnÃ©es de test $\Rightarrow$ `prediction.py`
5. ğŸ§ª Utilisation d'un **pipeline** `sklearn`
    - Evite le Data Leakage
    - ProcÃ©dure standardisÃ©e pour l'ensemble des modÃ¨les.

::: {.notes}
Mais Guillaume dis-moi, si on peut facilement voir l'intÃ©rÃªt de prÃ©dire le prix d'une bouteille de vin, quel est l'intÃ©rÃªt de prÃ©dire le type de vin ? Je veux dire, une fois qu'on regarde la bouteille, Ã  la couleur on peut savoir, Ã§a semble un peu bÃªte non ?

Eh bien Corentin, la rÃ©ponse Ã©tait Ã  Noel ! Quand, dans un repas de famille, on nous prÃ©sente pas moins d'une dizaine de vins et qu'on commence Ã  tous les goÃ»ter, il arrive ce moment inÃ©luctable ou on dÃ©passe les 2 grammes par litre, et Ã  ce moment... difficile de distinguer ce qu'on boit. Nos modÃ¨les viennent en aide Ã  ce moment lÃ  ! Enfin, si l'utilisateur arrive Ã  utiliser son ordinateur...

***

Le *Data Leakage* se produit lorsque des informations qui sont indisponibles au moment de la prÃ©diction sont utilisÃ©es pendant la construction du modÃ¨le. Se traduit par des estimations de performances trop optimistes, et donc de moins bonnes performances quand le modÃ¨le est utilisÃ© sur de nouvelles donnÃ©es.

- 80%/20% train/test
:::

## â¶ ML : Optimisation {.smaller}

1. Choix des **21 variables explicatives**
2. Preprocessing : `OneHotEncoder()`, Imputation NA, `MinMaxScaler()`
3. Optimisation des hyperparamÃ¨tres par Cross-Validation

- Avec `optimisation_script.py` on optimise les hyperparamÃ¨tres des modÃ¨les et on rÃ©cupÃ¨re sous forme de CSV :
    - Les scores de test et d'entrainement
    - Les Ã©carts-type $\sigma_{\text{test}}$ et $\sigma_{\text{train}}$
    - Les hyperparamÃ¨tres optimaux pour chaque modÃ¨le

```CSV
ModÃ¨le,Score Test,Score Entrainement,Ecart-Type Test,Ecart-Type Train,ParamÃ¨tres,Score Test data,Mode
Random Forest,0.934,0.941,0.007,0.007,"{'entrainement__max_depth': 9, 'entrainement__n_estimators': 30, 'imputation__strategy': 'median'}",0.9301745635910225,classification
K Neighbors,0.954,0.965,0.012,0.003,"{'entrainement__n_neighbors': 5, 'imputation__strategy': 'median'}",0.9600997506234414,classification
RÃ©seaux de neurones,0.976,0.997,0.007,0.001,"{'entrainement__hidden_layer_sizes': (100,), 'entrainement__max_iter': 1000, 'entrainement__solver': 'adam', 'imputation__strategy': 'median'}",0.9800498753117207,classification
Boosting,0.975,1.0,0.009,0.0,"{'entrainement__learning_rate': 0.5, 'entrainement__n_estimators': 200, 'imputation__strategy': 'median'}",0.9812967581047382,classification
Ridge,0.979,0.983,0.009,0.002,"{'entrainement__alpha': 0.015625, 'imputation__strategy': 'mean'}",0.9812967581047382,classification
Support Vector,0.981,0.992,0.008,0.002,"{'entrainement__C': 3.281341424030552, 'imputation__strategy': 'median'}",0.9825436408977556,classification
```

::: {.notes}

- variables & modÃ¨les qui serviront dans nos modÃ¨les 
- 6 modÃ¨les pour ne pas Ãªtre trop exhaustif (RF, Boosting, Ridge, MLP, KNN, SVM). 

- transforme une colonne catÃ©gorielle en plusieurs colonnes binaires

- optimisation des paramÃ¨tres  et strategie d'imputation par CV
- Pour chaque modÃ¨le on a decidÃ© d'optimiser entre 2 et 3 hyperparamÃ¨tre.

- rÃ©sultats stockÃ©s dans un CSV avec les score, et valeur des hyperparamÃ¨tres.
:::

## ğŸ¹ ML : PrÃ©diction {.smaller} 

- Deux types de prÃ©dictions :
    - **Classification** sur le type de vin (Vin Rouge / Blanc / RosÃ©)
    - **RÃ©gression** sur le prix d'une bouteille de vin
- Avec `prediction_script.py` on rÃ©alise les prÃ©dictions avec tous les modÃ¨les

```csv
name,type,random_forest,boosting,ridge,knn,mlp,support_vector
LES CARLINES 2021 - MAS HAUT BUIS,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge
LA BARGEMONE ROSE 2022 - COMMANDERIE DE LA BARGEMONE,Vin RosÃ©,Vin Blanc,Vin RosÃ©,Vin RosÃ©,Vin RosÃ©,Vin RosÃ©,Vin RosÃ©
TEMPRANILLO 2021- VEGA DEMARA,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge
CHÃ‚TEAUNEUF DU PAPE - ALCHIMIE 2020 - DOMAINE DES 3 CELLIER,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge
```

- Pour les 800 vins qui n'ont pas servi dans notre Cross Validation on rÃ©alise une prÃ©diction par chacun de nos 6 modÃ¨les, le tout stockÃ© dans un fichier CSV !

::: {.notes}

- prÃ©diction sur les 800 vins restants

- stock tous les rÃ©sultats dans un CSV, pour chaque vin on a la valeur rÃ©el et la prÃ©diction pour chaqu'un des modÃ¨les.
- 1 fichier pour la rÃ©gression et 1 pour classification

- Evaluation des modÃ¨les avec des mÃ©triques

:::

## ğŸ”¬ Metrics {.smaller}

- **Regression**:
    - Erreur moyenne absolue : MAE($y$,$\hat{y}$) = $\frac{1}{n}\sum|y_i - \hat{y_i}|$
    - Erreur quadratique moyenne : MSE($y$,$\hat{y}$) = $\frac{1}{n}\sum(y_i - \hat{y_i})^2$
    - Erreur RÃ©siduelle Maximale : MaxError($y$, $\hat{y}$) = $\max\left(|y_i-\hat{y_i}|\right)$
    - $R^2$ Score = $1- \frac{\sum(y_i-\hat{y_i})^2}{\sum(y_i-\bar{y_i})^2}$

- **Classification**:
    - Accuracy Score : AS($y$,$\hat{y}$) = $\frac{1}{n}\sum(\hat{y_i} = y_i)$
    - Precision = $\frac{\text{true positive}}{\text{true positive + false positive}}$
    - Recall = $\frac{\text{true positive}}{\text{true positive + false negative}}$
    - $F_1$ Score = $2 \times \frac{\text{precision } \times \text{ recall}}{\text{precision + recall}}$

::: {.notes}
Nous avons utilisÃ© un certains nombre de mÃ©triques implÃ©mentÃ©es dans `sklearn` pour Ã©valuer la qualitÃ© de nos modÃ¨les :

- La $MAE$ est en fait simplement la somme des erreurs absolues divisÃ©e par la taille de l'Ã©chantillon. 
- La $MSE$ mesure la moyenne des carrÃ©s des erreurs, c'est-Ã -dire la diffÃ©rence quadratique moyenne entre la valeur estimÃ©e et la valeur rÃ©elle.
- L'erreur rÃ©siduelle maximale est une mÃ©trique qui capture l'erreur la plus importante entre la valeur prÃ©dite et la valeur rÃ©elle.
- Le $R^2$ reprÃ©sente la proportion de variance de la variable Ã  prÃ©dire expliquÃ©e par les variables indÃ©pendantes du modÃ¨le. Il fournit une indication de la qualitÃ© de l'ajustement.

Afin de visualiser tous nos rÃ©sultats une application serait idÃ©ale...
:::

## ğŸ’» Application {.smaller background-image="img\st.png" background-opacity="0.25"}
ğŸ•µ **Framework** utilisÃ© : `streamlit`

- ğŸ¤· Pourquoi ? FacilitÃ© de mise en oeuvre
    - Base de donnÃ©es 
    - Statistiques descriptives (corrÃ©lations, rÃ©partition, etc.)
    - Machine Learning 
- ğŸ‘¨â€ğŸ­ Comment ? Forte flexibilitÃ© $\rightarrow$ L'utilisateur peut jouer avec les donnÃ©es
    - Sidebar avec de nombreux sÃ©lecteurs

<iframe src="https://giphy.com/embed/T7QRkgGzYdQju" width="480" height="240" frameBorder="0" class="giphy-embed" allowFullScreen style="display:block; margin:auto;"></iframe><p><a href="https://giphy.com/gifs/franceinfo-wtf-citation-T7QRkgGzYdQju"></a></p>

::: {.notes}

- FacilitÃ© d'utilisation, jeu de lego, bloc que l'on combine
- Parfait pour l'analyse de donnÃ©es, intÃ©gration des plotly aisÃ©
- l'utilisateur peut intÃ©ragir facilement avec les Ã©lements de l'app

Encore une fois aussi, l'API de `streamlit` est trÃ¨s bien documentÃ©e.

On peut arriver Ã  un rendu qui est vraiment convaincant niveau interface utilisateur sans utiliser de CSS ou de javascript !

Ecoute Arnaud, avant de passer au p'tit coup, on va parler de stockage avant !
:::

## Choix du stockage, Partie I

<i class="fa-solid fa-database"></i> `duckdb` : La base de donnÃ©es qui fait *"coin coin"* ğŸ¦†

```python
def db_connector() -> DuckDBPyConnection:
    """Se connecte Ã  la base de donnÃ©es."""
    connection = duckdb.connect(database=":memory:")
    return connection
```

- `:memory:` $\Rightarrow$ Base de donnÃ©es **in-memory**
- La base de donnÃ©es en mÃ©moire stocke les informations directement dans la mÃ©moire vive plutÃ´t que sur un disque.
- RÃ©duit le temps nÃ©cessaire au stockage et Ã  la consultation des donnÃ©es, et accÃ©lÃ¨re lâ€™exÃ©cution des requÃªtes.

:::{.notes}
Comme on l'a vu dans la partie **Optimisation** et **PrÃ©diction** du Machine Learning, on a des rÃ©sultats en CSV. Mais une fois qu'on a 4-5 csv Ã§a commence Ã  devenir encombrant...du coup on a plutÃ´t optÃ© pour une base de donnÃ©es. Et pas n'importe laquelle !

Une base de donnÃ©es *in-memory* est donc idÃ©ale pour une application effectuant de lâ€™analyse de donnÃ©es en temps rÃ©el comme la notre.
:::

## Choix du stockage, Partie II {.smaller}

- 5 tables de rÃ©sultats de Machine Learning sont obtenues grÃ¢ce Ã  l'exÃ©cution de `ml_trigger` qui se charge d'Ã©xÃ©cuter l'ensemble des scripts d'export. 

*Voici un schÃ©ma du processus d'ingestion des tables :*

```{mermaid}
graph LR;
A("ğŸ‘¨â€ğŸ”¬ pred_classification")-->F;
B("ğŸ‘¨â€ğŸ”¬ pred_regression")-->F;
C("ğŸ‘©â€ğŸ« result_ml_regression")-->F;
D("ğŸ‘©â€ğŸ« result_ml_classification")-->F;
E("ğŸ•µï¸â€â™‚ï¸ importance")-->F[("ğŸ¦† In Memory Database")];

style A stroke:#adbac7,stroke-width:3px, fill:white;
style B stroke:#adbac7,stroke-width:3px, fill:white;
style C stroke:#adbac7,stroke-width:3px, fill:white;
style D stroke:#adbac7,stroke-width:3px, fill:white;
style E stroke:#adbac7,stroke-width:3px, fill:white;
style F stroke:#fff100,stroke-width:3px, fill:white;
```

## ğŸš€ DÃ©monstration

**Lancement de l'application, 2 MÃ©thodes.** 

:::{.callout-note}

## **Depuis un terminal** :

- *Lancement du shell poetry* : 

```powershell
py -m poetry shell
```

- *Lancement de l'application* :

```powershell
python -m streamlit run "streamlit_app.py"
```
:::


:::{.callout-note}

## **Depuis le lien de l'application dÃ©ployÃ©e sur le cloud `streamlit`** :

- **Lien** : [https://wine-scraping.streamlit.app/ <i class="fa-solid fa-up-right-from-square"></i>](https://wine-scraping.streamlit.app/)

:::

:::{.notes}
On a deux mÃ©thodes pour lancer notre application. Je dirais mÃªme, comme un vieil adage le dit : **Jamais deux sans trois** ! Sauf que la troisiÃ¨me mÃ©thode on va la garder pour plus tard en bonus. 

La diffÃ©rence entre les deux premiÃ¨res mÃ©thodes c'est que l'une va tourner en local alors que l'autre est sur le cloud streamlit. Le dÃ©ploiement sur le cloud est assez simple : on link le repo Github, `poetry`  installe les dÃ©pendances et c'est parti ğŸš€.
:::


## Un code de *Deutsche QualitÃ¤t* {.smaller background-image="img\deutsche_qualitat.png" background-opacity="0.25"}

- Annotations de type claires
- Docstrings explicites et soignÃ©es
- Gestion des dÃ©pendances avec Poetry
- ModularitÃ©
- Tests des features de l'application 
- Docker

**Code certifiÃ© conforme par l'*Agent Smith$^*$***

$^*$ *L'Agent Smith tient par ailleurs Ã  prÃ©ciser qu'il n'a reÃ§u aucun pot-de-vin de notre part pour ce diagnostic malgrÃ© son enrichissement personnel fulgurant...*

:::{.notes}
- Tous les modules ont leur tests associÃ©s
:::

## Annotations de type {.smaller}

```python
def model_rf(x_train: pd.DataFrame, y_train: pd.Series, mode: str) -> GridSearchCV:
    ...
```

- Expliciter au maximum les types d'entrÃ©e et de sortie des fonctions.
- On peut parler de **documentation implicite** $\Rightarrow$ on cherche Ã  Ã©viter Ã  un utilisateur d'utiliser des objets incompatibles avec ce qui a Ã©tÃ© Ã©tabli.

:::{.callout-note}

`mypy` va nous permettre d'effectuer ce contrÃ´le *(static type checking)*, c'est Ã  dire de vÃ©rifier si les valeurs assignÃ©es aux variables, les arguments passÃ©s aux fonctions et les valeurs de retour correspondent aux types attendus.

:::

## Docstrings {.smaller}

- Chaque fonction Ã  interface publique possÃ¨de une docstring structurÃ©e :
    - Nom de la fonction et description succinte
    - ParamÃ¨tre(s) d'entrÃ©e et paramÃ¨tre(s) de sortie  
    - LevÃ©e d'exception (si il y en a)
    - Au minimum un exemple d'utilisation

*Exemple* avec la fonction `model_rf` du module `models.py` : 

```python
"""`model_rf`: Effectue une recherche exhaustive (Cross-Validation) des meilleurs paramÃ¨tres
    en utilisant une Random Forest. Les paramÃ¨tres optimisÃ©s sont :

    - n_estimators
    - max_depth

    ---------
    `Parameters`
    --------- ::

        x_train (pd.DataFrame): # L'ensemble d'entrainement
        y_train (pd.Series): # La variable Ã  prÃ©dire
        mode (str): # regression | classification

    `Raises`
    --------- ::

        ValueError: # Une erreur est levÃ©e quand le mode est invalide

    `Returns`
    --------- ::

        GridSearchCV

    `Example(s)`
    ---------

    >>> model_rf(x_train=X_train, y_train=y_train, mode = "regression")
    ... Entrainement du modÃ¨le : Random Forest
    ... GridSearchCV(estimator=Pipeline(steps=[('imputation', SimpleImputer()),
    ...                                   ('echelle', MinMaxScaler()),
    ...                                   ('entrainement',
    ...                                    RandomForestRegressor())]),
    ...         n_jobs=-1,
    ...         param_grid={'entrainement__max_depth': range(1, 10),
    ...                     'entrainement__n_estimators': range(10, 50, 10),
    ...                     'imputation__strategy': ['mean', 'median',
    ...                                              'most_frequent']},
    ...         return_train_score=True)
    """
```

::: {.notes}
- Un vrai petit tutoriel pour chaque fonction
- Description 
- ParamÃ¨tres
- Raises en cas de potentiel erreur
- Return
- Exemple d'utilisation

Mais bon c'est bien beau ces lignes de description, pourrais-tu Ãªtre un peu plus poÃ©tique ?
:::

## ğŸ§™â€â™‚ï¸ Poetry {.smaller}

**Gestion des dÃ©pendances** : `poetry` simplifie la gestion des dÃ©pendances en utilisant un fichier de configuration pyproject.toml. Il permet de spÃ©cifier les dÃ©pendances directes et les dÃ©pendances de dÃ©veloppement requises pour le projet.

**Environnement Virtuel** : venv isolÃ© pour le projet, aidant Ã  maintenir un environnement de dÃ©veloppement propre et Ã©vitant les conflits entre les versions des packages.

**Installation de dÃ©pendances** : Facilite l'installation des dÃ©pendances dÃ©finies dans le fichier de configuration en utilisant la commande `poetry install`.

```powershell
py -m poetry install
```

::: {.notes}
Eh bien Guillaume, avec `poetry` on va faire rimer nos dÃ©pendances !

Rapidement, on a dÃ©cidÃ© d'opter pour `poetry` car le moment fatidique ou un d'entre nous dÃ©cide d'installer localemet un package et que l'autre ne l'a pas arrivait un peu trop souvent et Ã§a c'Ã©tait pas super poÃ©tique justement.
:::


## ğŸš¢ Modulaire !{.smaller}

SÃ©paration des composants du projet :

```
â”œâ”€â”€â”€data
â”‚   â”œâ”€â”€â”€ğŸ·vins.json
â”‚   â”œâ”€â”€â”€ğŸ’¾wine_links.csv
â”‚   â””â”€â”€â”€tables
â”‚       â”œâ”€â”€â”€ğŸ’¾pred_classification.csv
â”‚       â”œâ”€â”€â”€ğŸ’¾pred_regression.csv
â”‚       â”œâ”€â”€â”€ğŸ’¾result_ml_classification.csv
â”‚       â””â”€â”€â”€ğŸ’¾result_ml_regression.csv
â”‚       â””â”€â”€â”€ğŸ’¾importance.csv
â”œâ”€â”€â”€src
â”‚   â””â”€â”€â”€ğŸ“¦modules
â”‚       â”œâ”€â”€â”€âš™app
â”‚       â”‚   â”œâ”€â”€â”€ğŸst_functions.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸst_plots.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸst_selectors.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸst_tables.py
â”‚       â”‚   â””â”€â”€â”€ğŸst_tables.py
â”‚       â”œâ”€â”€â”€âš™ml_models
â”‚       â”‚   â”œâ”€â”€â”€ğŸimportance_script.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸmodels.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸoptimisation_script.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸprediction_script.py
â”‚       â”‚   â””â”€â”€â”€ğŸprediction.py
â”‚       â”œâ”€â”€â”€âš™scraping
â”‚       â”‚   â”œâ”€â”€â”€ğŸmystical_soup.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸpage_scraper.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸscraping_functions.py
â”‚       â”‚   â”œâ”€â”€â”€ğŸvin_dataclass.py
â”‚       â”‚   â””â”€â”€â”€ğŸwine_scraper.py
â”‚       â”œâ”€â”€â”€ğŸml_trigger.py
â”‚       â”œâ”€â”€â”€ğŸscraping_trigger.py
â”‚       â”œâ”€â”€â”€ğŸbear_cleaner.py
â”‚       â””â”€â”€â”€ğŸutils.py
â”œâ”€â”€â”€ğŸ³Dockerfile
â”œâ”€â”€â”€ğŸ§™â€â™‚ï¸poetry.lock
â”œâ”€â”€â”€ğŸ“pyproject.toml
â”œâ”€â”€â”€ğŸ“˜README.md
â””â”€â”€â”€ğŸstreamlit_app.py
```

::: {.notes}
- Le projet commenÃ§ant a Ãªtre bien fourni, nÃ©cÃ©ssitÃ© de modulariser le tout pour apporter un peu de clartÃ© pour le dÃ©veloppeur.
:::

## ğŸ³ Docker, Partie I {.smaller}

**Pourquoi utiliser Docker ?**

**Isolation** : Docker permet d'isoler l'application, ses dÃ©pendances et son environnement d'exÃ©cution dans un conteneur. Cela signifie que l'application s'exÃ©cute avec ses propres ressources et dÃ©pendances sans affecter l'environnement hÃ´te.

**PortabilitÃ©** : Une fois que l'image Docker est crÃ©Ã©e, elle peut Ãªtre exÃ©cutÃ©e sur n'importe quel systÃ¨me prenant en charge Docker, offrant une portabilitÃ© Ã©levÃ©e.

<hr>

**Comment ?** $\Rightarrow$ `Dockerfile`

Docker assure la reproductibilitÃ© en permettant Ã  n'importe qui de construire et d'exÃ©cuter le **mÃªme conteneur** Ã  partir des spÃ©cifications dÃ©finies dans le `Dockerfile`.

:::{.notes}
Le `Dockerfile` spÃ©cifie les Ã©tapes pour installer les dÃ©pendances de l'application (dans ce cas, on va utiliser `poetry` pour gÃ©rer les dÃ©pendances) et configurer un environnement minimaliste Ã  l'intÃ©rieur du conteneur.
:::

## ğŸ³ Docker, Partie II {.smaller}

- *Contenu du `Dockerfile` :*

```{.Dockerfile code-line-numbers="|1|2|4|6-8|10-13|15-16|18|20|22|24|"}
FROM python:3.10-slim-buster
WORKDIR /app

COPY pyproject.toml poetry.lock ./

RUN pip install poetry \ 
    && poetry config virtualenvs.create false \
    && poetry install --no-dev --no-interaction --no-ansi

COPY streamlit_app.py .
COPY src ./src
COPY data ./data
COPY img ./img

RUN addgroup --system app \
    && adduser --system --group app

USER app

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

ENTRYPOINT ["python", "-m", "streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

:::{.notes}
Regardons plus en dÃ©tail ce que contient ce `Dockerfile`. 

FROM python:3.10-slim-buster

1. **FROM python:3.10-slim-buster** $\Rightarrow$ spÃ©cifie l'image de base Ã  partir de laquelle notre image Docker sera construite. On utilise l'image Python *3.10-slim-buster* comme base. Cette image *slim-buster* est une version rÃ©duite plus rapide de l'image complÃ¨te avec le minimum de dÃ©pendances possible.
2. **WORKDIR /app** $\Rightarrow$ dÃ©finit le rÃ©pertoire de travail dans le conteneur. Toutes les instructions suivantes sont exÃ©cutÃ©es Ã  partir de ce rÃ©pertoire.
3. **COPY pyproject.toml poetry.lock ./** $\Rightarrow$ copie les fichiers pyproject.toml et poetry.lock depuis le rÃ©pertoire local dans le rÃ©pertoire *app* du conteneur.
4. **RUN pip install poetry && poetry config virtualenvs.create false && poetry install --no-dev --no-interaction --no-ansi** $\Rightarrow$ ExÃ©cute plusieurs commandes en une seule instruction RUN :
    - On installe `poetry` dans le conteneur via pip.
    - On configure `poetry` pour ne pas crÃ©er d'environnement virtuel.
    - On Installe les dÃ©pendances du projet Ã  partir de poetry.lock, en excluant les dÃ©pendances de dÃ©veloppement (--no-dev), sans interaction (--no-interaction) et sans afficher de couleurs ANSI (--no-ansi). En effet, on ne copie pas nos tests dans le conteneur, Ã§a alourdirait l'image pour rien.
5. **COPY streamlit_app.py** $\Rightarrow$ On copie le fichier `streamlit_app.py`, le dossier `src`, `data` et `img` depuis le rÃ©pertoire local dans le rÃ©pertoire *app* du conteneur.
6. **RUN addgroup --system app && adduser --system --group app** $\Rightarrow$ CrÃ©e un groupe systÃ¨me appelÃ© app et un utilisateur systÃ¨me Ã©galement appelÃ© app - **On veut ABSOLUMENT Ã©viter d'utiliser l'utilisateur root donc c'est pas pour Ã§a qu'on configure un utilisateur**
7. **USER app** $\Rightarrow$ DÃ©finit l'utilisateur qui exÃ©cutera les commandes suivantes dans le conteneur comme Ã©tant l'utilisateur **app**.
8. **EXPOSE 8501** $\Rightarrow$ Expose le port 8501. Indique simplement quel port qui doit Ãªtre publiÃ© lors de l'exÃ©cution de l'image.
9. **HEALTHCHECK** $\Rightarrow$ Pour tester si le conteneur fonctionne toujours correctement.
10. **ENTRYPOINT** $\Rightarrow$ DÃ©finit la commande d'entrÃ©e Ã  exÃ©cuter quand le conteneur basÃ© sur l'image est dÃ©marrÃ©. Dans notre cas, on fait un streamlit run de notre application sur le port 8501.
:::

## ğŸ—ï¸ Le conteneur en action ! {.smaller}

Il faut tout d'abord s'assurer d'avoir tÃ©lÃ©chargÃ© **Docker Desktop** avant toute chose.

Une fois installÃ©, l'image est construite en exÃ©cutant la commande suivante dans un terminal :

```powershell
docker image build . -t "wine_scraping"
```

Une fois la crÃ©ation de l'image terminÃ©e, on peut consulter la taille de celle-ci avec :

```powershell
docker images
```

Ensuite, pour lancer le conteneur Docker avec l'utilisateur *app* sur le port initial (8501) de `streamlit`, il suffit de faire :

```powershell
docker run -u app -p 8501:8501 wine_scraping
```

ğŸ‰ Une fois le conteneur lancÃ©, on le voit apparaitre dans **Docker Desktop**. Pour accÃ©der Ã  l'application, il faut se rendre sur [*http://localhost:8501/*](http://localhost:8501/).

## Fin {.smaller background-image="img\weird_man.png" background-opacity="0.25"}

> On ne sait pas pourquoi on a fait tout Ã§a, car nous voulions simplement trouver une bouteille pour fÃªter notre anniversaire, et on se retrouve avec une application d'analyse de donnÃ©es qui ne nous aide en aucun cas Ã  trouver notre breuvage...ğŸ˜µ

## RÃ©fÃ©rences

- Images : **DALL-E**
