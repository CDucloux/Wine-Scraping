---
title: "üç∑ √Ä boire üçª"
subtitle: "*Le breuvage contre-attaque*"
author: "`Guillaume DEVANT` & `Corentin DUCLOUX`"
format: 
    revealjs:
        theme: [serif, custom.scss]
        background-transition: fade
        transition: slide
        navigation-mode: linear
        footer: "**Machine Learning**"
        logo: https://corentinducloux.fr/dossier_img/mecen_transparent.png
---


## Introduction {background-image="img\territoire_vin.png" background-opacity="0.5"}

<link rel="stylesheet" 
href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

<link href='https://fonts.googleapis.com/css?family=Fira Code' rel='stylesheet'>


- Une immersion en territoire alcoolis√© s'impose...
<div style="display: flex; justify-content: center; align-items: center; height: 60vh;">
<iframe width="800" height="340" src="https://www.youtube.com/embed/mZ6xNxpuIOQ" title="Bodh&#39;Aktan - √Ä boire" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div>

## Le *Pourquoi* du *Comment* {background-image="img\bouteille_dieu.png" background-opacity="0.5"}

- Le 18 janvier approche, une date en apparence anodine mais tr√®s importante pour nos deux comp√®res.
- Pour cette journ√©e festive, nos 2 protagonistes se rendirent sur `vinatis.com` pour trouver un breuvage.
- Et c'est √† ce moment que l'histoire prend **racine**...

::: {.fragment}
::: {.fragment .grow}
![](img\racine.jpg){fig-align="center" height="120"}
:::
::: {.fragment}
**On parle de moi ?**
:::
:::

::: {.notes}
- Nous avons commenc√© √† rechercher notre proie d√®s fin septembre pour faire quelques tests, notamment sur la partie scraping.
:::

## Scraping {background-image="img\bouteille_scrap.png" background-opacity="0.5"}

> *‚ÄúPour savoir qu'un verre √©tait de trop, encore faut-il avoir scrap√© son vin !‚Äù* $-$ **Inconnu**

::: {.notes}
Eh non Jean ! On ne parle pas de toi mais bien du scraping de vin. D'ailleurs on voit au tableau ce magnifique proverbe indon√©so-inconnu qui √©nonce que **Pour savoir qu'un verre √©tait de trop, encore faut-il avoir scrap√© son vin !**

Ca t'a ouvert les chakras Guillaume ? Ouais, non ? Bon moi non plus, et si on passait √† la partie technique plut√¥t ?
:::

## Scraping, Partie I {.smaller}

`scraping_functions.py` $\Rightarrow$ Le coeur du scraper

1. Construit des URL avec *query parameters* en utilisant le package `yarl`.

```python
URL_INIT = URL.build(scheme="https", host="vinatis.com")
WHITE = "achat-vin-blanc"
RED = "achat-vin-rouge"
ROSE = "achat-vin-rose"

>>> URL_INIT / WHITE % {"page": 1, "tri": 7}
... URL('https://vinatis.com/achat-vin-blanc?page=1&tri=7')
```

2. `create_session` cr√©e une session HTML avec un User-Agent et un Proxy al√©atoire, pouvant changer entre les requ√™tes.
3. Poss√®de un d√©corateur `@random_waiter(min, max)` permettant de g√©n√©rer un temps d'attente al√©atoire entre les deux bornes sp√©cifi√©es entre chaque requ√™te **GET** pour √©viter d'envoyer trop de requ√™tes dans un laps de temps r√©duit.
4. `create_all_wine_urls` permet de cr√©er l'ensemble des liens **href**.
5. `export_wine_links` permet d'exporter ces liens dans un fichier CSV.

::: {.notes}
Pour un peu de mise en contexte, initialement on avait commenc√© par scraper les pages de vente de vins o√π une trentaine de vins sont affich√©s...mais on s'est rapidement rendu compte que dans ces pages, il manquait beaucoup d'informations. On s'est plut√¥t mis en t√™te de r√©cup√©rer les caract√©ristiques sur chaque page individuelle de vin, qu'on peut facilement r√©cup√©rer sur les pages de recherche gr√¢ce √† des liens href. Et initialement, on l'avait fait avec `Selenium` mais √ßa prenait un temps monstre donc on a chang√© d'id√©e.

*Note* : On aurait pu construire les URL √† la main mais c'√©tait beaucoup moins √©l√©gant que de le faire comme √ßa.

- Ensuite on a voulu introduire un User Agent r√©aliste quand on effectue notre requ√™te get, pour √©viter que le site ne finisse par comprendre que c'est un bot. Ca permet simplement d'envoyer des en-t√™tes que renvoierai un navigateur comme Firefox, Chrome ou Edge. 
- Le proxy permet quant √† lui de masquer son adresse IP, au cas o√π on finirait par se faire bannir.
- On a aussi voulu √©viter de surcharger les serveurs en envoyant trop de requ√™tes en m√™me temps donc on a utilis√© un d√©corateur (**point 3**)

Cela √©tant, on a eu aucun probl√®me jusqu'ici chaque fois qu'on a fait le scraping. 
:::

## Scraping, Partie II {.smaller}

1. On va ensuite requ√™ter ces liens **href** avec `create_json` et r√©cup√©rer les pages brutes en HTML.
2. La fonction `scraping` du module `mystical_soup` va permettre d'extraire toutes les informations int√©ressantes de la page brute et renvoyer la dataclass `Vin` s√©rialisable en *JSON*.

<i class="fa-solid fa-wine-bottle"></i> *Exemple* d'un `Vin` et ses caract√©ristiques s√©rialis√©s en *JSON* :

```json
{
        "name": "PINOT NOIR 2019 LAS PIZARRAS - ERRAZURIZ",
        "capacity": "0,75 L",
        "price": "94,90 ‚Ç¨",
        "price_bundle": null,
        "characteristics": "Vin Rouge / Chili / Central Valley / Aconcagua Valley DO / 13,5 % vol / 100% Pinot noir",
        "note": null,
        "keywords": [
            "El√©gance",
            "Finesse",
            "Harmonie"
        ],
        "others": null,
        "picture": "https://www.vinatis.com/67234-detail_default/pinot-noir-2019-las-pizarras-errazuriz.png",
        "classification": null,
        "millesime": "2019",
        "cepage": "100% Pinot noir",
        "gouts": "Rouge Charnu et fruit√©",
        "par_gouts": "Puissant",
        "oeil": "Robe rubis aux reflets violets.",
        "nez": "Nez complexe sur la griotte, les √©pices et les champignons (truffe).",
        "bouche": "Bouche fruit√©e et florale. Tanins structur√©s, √©l√©gants et fins. finale harmonieuse et persistante.",
        "temperature": "8-10¬∞C",
        "service": "En bouteille ou en carafe",
        "conservation_1": "2026",
        "conservation_2": "A boire et √† garder",
        "accords_vins": "Ap√©ritif, Entr√©e, Charcuterie, Viande rouge, Viande blanche, Volaille, Gibier, Champignon, Barbecue, Cuisine du monde, Fromage, Dessert fruit√©, Dessert chocolat√©",
        "accords_reco": "Gigot d'agneau aux herbes de Provence; Tikka massala; Plateau de fromages."
    }
```

::: {.notes}

Une fois que l'on a r√©cup√©r√© tous les URLs des pages des vins, on va scraper chaque page avec le module `mystical_soup`. Toutes les informations qui nous int√©resse sont stock√© dans un fichier JSON.

:::

## üßπ Cleaning {.smaller background-image="img\pandas_vs_polars.png" background-opacity="0.25"}

Mais ce *JSON* **brut** doit √™tre nettoy√© et consid√©rablement restructur√© !

1. Nous avons choisi d'utiliser `polars` üêª et non pas `pandas` üêº pour le faire.
2. Toutes les fonctions de nettoyage sont contenues dans `bear_cleaner.py`.
3. La fonction `super_pipe` permet de chainer toutes les transformations dans un pipeline propre pour structurer notre **Dataframe**.
4. Nous obtenons ainsi un **Dataframe** de taille `(4006,40)` pr√™t pour le Machine Learning 

![](img\bear_data.png){fig-align="center"}

::: {.notes}
On l'a vu avec l'exemple d'un vin s√©rialis√© en json sur la slide pr√©c√©dente, les entr√©es ne sont pas nettoy√©es : les valeurs num√©riques sont stock√©es sous forme de texte, etc.

**Pourquoi polars ?** $\Rightarrow$ Les expressions polars nous permettent de faire tout un tas d'op√©rations sans jamais utiliser des lambda functions, l'API est mieux document√©e.

- En sortie : 4006 vins distincts et 40 variables !
:::

## Machine Learning {background-image="img\bouteille_ecole.png" background-opacity="0.25"}

> *‚Äú2024 sera un mill√©sime fran√ßais !‚Äù* $-$ **Emmanuel Macron**

## Machine Learning - Proc√©dure {.smaller background-image="img\pipeline.png" background-opacity="0.25"}

1. Deux variables √† pr√©dire : *unit_price* & *type*
2. Utilisation de 6 mod√®les de **Machine Learning**
3. ‚û∂ Optimisation des hyperparam√®tres $\Rightarrow$ `models.py`
4. üèπ Pr√©diction sur les donn√©es de test $\Rightarrow$ `prediction.py`
5. üß™ Utilisation d'un **pipeline** `sklearn`
    - Evite le Data Leakage
    - Proc√©dure standardis√©e pour l'ensemble des mod√®les.

::: {.notes}
Mais Guillaume dis-moi, si on peut facilement voir l'int√©r√™t de pr√©dire le prix d'une bouteille de vin, quel est l'int√©r√™t de pr√©dire le type de vin ? Je veux dire, une fois qu'on regarde la bouteille, √† la couleur on peut savoir, √ßa semble un peu b√™te non ?

Eh bien Corentin, la r√©ponse √©tait √† Noel ! Quand, dans un repas de famille, on nous pr√©sente pas moins d'une dizaine de vins et qu'on commence √† tous les go√ªter, il arrive ce moment in√©luctable ou on d√©passe les 2 grammes par litre, et √† ce moment... difficile de distinguer ce qu'on boit. Nos mod√®les viennent en aide √† ce moment l√† ! Enfin, si l'utilisateur arrive √† utiliser son ordinateur...

***

Le *Data Leakage* se produit lorsque des informations qui sont indisponibles au moment de la pr√©diction sont utilis√©es pendant la construction du mod√®le. Se traduit par des estimations de performances trop optimistes, et donc de moins bonnes performances quand le mod√®le est utilis√© sur de nouvelles donn√©es.

- 80%/20% train/test
:::

## ‚û∂ ML : Optimisation {.smaller}

1. Choix des **21 variables explicatives**
2. Preprocessing : `OneHotEncoder()`, Imputation NA, `MinMaxScaler()`
3. Optimisation des hyperparam√®tres par Cross-Validation

- Avec `optimisation_script.py` on optimise les hyperparam√®tres des mod√®les et on r√©cup√®re sous forme de CSV :
    - Les scores de test et d'entrainement
    - Les √©carts-type $\sigma_{\text{test}}$ et $\sigma_{\text{train}}$
    - Les hyperparam√®tres optimaux pour chaque mod√®le

```CSV
Mod√®le,Score Test,Score Entrainement,Ecart-Type Test,Ecart-Type Train,Param√®tres,Score Test data,Mode
Random Forest,0.934,0.941,0.007,0.007,"{'entrainement__max_depth': 9, 'entrainement__n_estimators': 30, 'imputation__strategy': 'median'}",0.9301745635910225,classification
K Neighbors,0.954,0.965,0.012,0.003,"{'entrainement__n_neighbors': 5, 'imputation__strategy': 'median'}",0.9600997506234414,classification
R√©seaux de neurones,0.976,0.997,0.007,0.001,"{'entrainement__hidden_layer_sizes': (100,), 'entrainement__max_iter': 1000, 'entrainement__solver': 'adam', 'imputation__strategy': 'median'}",0.9800498753117207,classification
Boosting,0.975,1.0,0.009,0.0,"{'entrainement__learning_rate': 0.5, 'entrainement__n_estimators': 200, 'imputation__strategy': 'median'}",0.9812967581047382,classification
Ridge,0.979,0.983,0.009,0.002,"{'entrainement__alpha': 0.015625, 'imputation__strategy': 'mean'}",0.9812967581047382,classification
Support Vector,0.981,0.992,0.008,0.002,"{'entrainement__C': 3.281341424030552, 'imputation__strategy': 'median'}",0.9825436408977556,classification
```

::: {.notes}

- variables & mod√®les qui serviront dans nos mod√®les 
- 6 mod√®les pour ne pas √™tre trop exhaustif (RF, Boosting, Ridge, MLP, KNN, SVM). 

- transforme une colonne cat√©gorielle en plusieurs colonnes binaires

- optimisation des param√®tres  et strategie d'imputation par CV
- Pour chaque mod√®le on a decid√© d'optimiser entre 2 et 3 hyperparam√®tre.

- r√©sultats stock√©s dans un CSV avec les score, et valeur des hyperparam√®tres.
:::

## üèπ ML : Pr√©diction {.smaller} 

- Deux types de pr√©dictions :
    - **Classification** sur le type de vin (Vin Rouge / Blanc / Ros√©)
    - **R√©gression** sur le prix d'une bouteille de vin
- Avec `prediction_script.py` on r√©alise les pr√©dictions avec tous les mod√®les

```csv
name,type,random_forest,boosting,ridge,knn,mlp,support_vector
LES CARLINES 2021 - MAS HAUT BUIS,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge
LA BARGEMONE ROSE 2022 - COMMANDERIE DE LA BARGEMONE,Vin Ros√©,Vin Blanc,Vin Ros√©,Vin Ros√©,Vin Ros√©,Vin Ros√©,Vin Ros√©
TEMPRANILLO 2021- VEGA DEMARA,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge
CH√ÇTEAUNEUF DU PAPE - ALCHIMIE 2020 - DOMAINE DES 3 CELLIER,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge,Vin Rouge
```

- Pour les 800 vins qui n'ont pas servi dans notre Cross Validation on r√©alise une pr√©diction par chacun de nos 6 mod√®les, le tout stock√© dans un fichier CSV !

::: {.notes}

- pr√©diction sur les 800 vins restants

- stock tous les r√©sultats dans un CSV, pour chaque vin on a la valeur r√©el et la pr√©diction pour chaqu'un des mod√®les.
- 1 fichier pour la r√©gression et 1 pour classification

- Evaluation des mod√®les avec des m√©triques

:::

## üî¨ Metrics {.smaller}

- **Regression**:
    - Erreur moyenne absolue : MAE($y$,$\hat{y}$) = $\frac{1}{n}\sum|y_i - \hat{y_i}|$
    - Erreur quadratique moyenne : MSE($y$,$\hat{y}$) = $\frac{1}{n}\sum(y_i - \hat{y_i})^2$
    - Erreur R√©siduelle Maximale : MaxError($y$, $\hat{y}$) = $\max\left(|y_i-\hat{y_i}|\right)$
    - $R^2$ Score = $1- \frac{\sum(y_i-\hat{y_i})^2}{\sum(y_i-\bar{y_i})^2}$

- **Classification**:
    - Accuracy Score : AS($y$,$\hat{y}$) = $\frac{1}{n}\sum(\hat{y_i} = y_i)$
    - Precision = $\frac{\text{true positive}}{\text{true positive + false positive}}$
    - Recall = $\frac{\text{true positive}}{\text{true positive + false negative}}$
    - $F_1$ Score = $2 \times \frac{\text{precision } \times \text{ recall}}{\text{precision + recall}}$

::: {.notes}
Nous avons utilis√© un certains nombre de m√©triques impl√©ment√©es dans `sklearn` pour √©valuer la qualit√© de nos mod√®les :

- La $MAE$ est en fait simplement la somme des erreurs absolues divis√©e par la taille de l'√©chantillon. 
- La $MSE$ mesure la moyenne des carr√©s des erreurs, c'est-√†-dire la diff√©rence quadratique moyenne entre la valeur estim√©e et la valeur r√©elle.
- L'erreur r√©siduelle maximale est une m√©trique qui capture l'erreur la plus importante entre la valeur pr√©dite et la valeur r√©elle.
- Le $R^2$ repr√©sente la proportion de variance de la variable √† pr√©dire expliqu√©e par les variables ind√©pendantes du mod√®le. Il fournit une indication de la qualit√© de l'ajustement.

Afin de visualiser tous nos r√©sultats une application serait id√©ale...
:::

## üíª Application {.smaller background-image="img\st.png" background-opacity="0.25"}
üïµ **Framework** utilis√© : `streamlit`

- ü§∑ Pourquoi ? Facilit√© de mise en oeuvre
    - Base de donn√©es 
    - Statistiques descriptives (corr√©lations, r√©partition, etc.)
    - Machine Learning 
- üë®‚Äçüè≠ Comment ? Forte flexibilit√© $\rightarrow$ L'utilisateur peut jouer avec les donn√©es
    - Sidebar avec de nombreux s√©lecteurs

<iframe src="https://giphy.com/embed/T7QRkgGzYdQju" width="480" height="240" frameBorder="0" class="giphy-embed" allowFullScreen style="display:block; margin:auto;"></iframe><p><a href="https://giphy.com/gifs/franceinfo-wtf-citation-T7QRkgGzYdQju"></a></p>

::: {.notes}

- Facilit√© d'utilisation, jeu de lego, bloc que l'on combine
- Parfait pour l'analyse de donn√©es, int√©gration des plotly ais√©
- l'utilisateur peut int√©ragir facilement avec les √©lements de l'app

Encore une fois aussi, l'API de `streamlit` est tr√®s bien document√©e.

On peut arriver √† un rendu qui est vraiment convaincant niveau interface utilisateur sans utiliser de CSS ou de javascript !

Ecoute Arnaud, avant de passer au p'tit coup, on va parler de stockage avant !
:::

## Choix du stockage, Partie I

<i class="fa-solid fa-database"></i> `duckdb` : La base de donn√©es qui fait *"coin coin"* ü¶Ü

```python
def db_connector() -> DuckDBPyConnection:
    """Se connecte √† la base de donn√©es."""
    connection = duckdb.connect(database=":memory:")
    return connection
```

- `:memory:` $\Rightarrow$ Base de donn√©es **in-memory**
- La base de donn√©es en m√©moire stocke les informations directement dans la m√©moire vive plut√¥t que sur un disque.
- R√©duit le temps n√©cessaire au stockage et √† la consultation des donn√©es, et acc√©l√®re l‚Äôex√©cution des requ√™tes.

:::{.notes}
Comme on l'a vu dans la partie **Optimisation** et **Pr√©diction** du Machine Learning, on a des r√©sultats en CSV. Mais une fois qu'on a 4-5 csv √ßa commence √† devenir encombrant...du coup on a plut√¥t opt√© pour une base de donn√©es. Et pas n'importe laquelle !

Une base de donn√©es *in-memory* est donc id√©ale pour une application effectuant de l‚Äôanalyse de donn√©es en temps r√©el comme la notre.
:::

## Choix du stockage, Partie II {.smaller}

- 5 tables de r√©sultats de Machine Learning sont obtenues gr√¢ce √† l'ex√©cution de `ml_trigger` qui se charge d'√©x√©cuter l'ensemble des scripts d'export. 

*Voici un sch√©ma du processus d'ingestion des tables :*

```{mermaid}
graph LR;
A("üë®‚Äçüî¨ pred_classification")-->F;
B("üë®‚Äçüî¨ pred_regression")-->F;
C("üë©‚Äçüè´ result_ml_regression")-->F;
D("üë©‚Äçüè´ result_ml_classification")-->F;
E("üïµÔ∏è‚Äç‚ôÇÔ∏è importance")-->F[("ü¶Ü In Memory Database")];

style A stroke:#adbac7,stroke-width:3px, fill:white;
style B stroke:#adbac7,stroke-width:3px, fill:white;
style C stroke:#adbac7,stroke-width:3px, fill:white;
style D stroke:#adbac7,stroke-width:3px, fill:white;
style E stroke:#adbac7,stroke-width:3px, fill:white;
style F stroke:#fff100,stroke-width:3px, fill:white;
```

## üöÄ D√©monstration

**Lancement de l'application, 2 M√©thodes.** 

:::{.callout-note}

## **Depuis un terminal** :

- *Lancement du shell poetry* : 

```powershell
py -m poetry shell
```

- *Lancement de l'application* :

```powershell
python -m streamlit run "streamlit_app.py"
```
:::


:::{.callout-note}

## **Depuis le lien de l'application d√©ploy√©e sur le cloud `streamlit`** :

- **Lien** : [https://wine-scraping.streamlit.app/ <i class="fa-solid fa-up-right-from-square"></i>](https://wine-scraping.streamlit.app/)

:::

:::{.notes}
On a deux m√©thodes pour lancer notre application. Je dirais m√™me, comme un vieil adage le dit : **Jamais deux sans trois** ! Sauf que la troisi√®me m√©thode on va la garder pour plus tard en bonus. 

La diff√©rence entre les deux premi√®res m√©thodes c'est que l'une va tourner en local alors que l'autre est sur le cloud streamlit. Le d√©ploiement sur le cloud est assez simple : on link le repo Github, `poetry`  installe les d√©pendances et c'est parti üöÄ.
:::


## Un code de *Deutsche Qualit√§t* {.smaller background-image="img\deutsche_qualitat.png" background-opacity="0.25"}

- Annotations de type claires
- Docstrings explicites et soign√©es
- Gestion des d√©pendances avec Poetry
- Modularit√©
- Tests des features de l'application 
- Docker

**Code certifi√© conforme par l'*Agent Smith$^*$***

$^*$ *L'Agent Smith tient par ailleurs √† pr√©ciser qu'il n'a re√ßu aucun pot-de-vin de notre part pour ce diagnostic malgr√© son enrichissement personnel fulgurant...*

:::{.notes}
- Tous les modules ont leur tests associ√©s
:::

## Annotations de type {.smaller}

```python
def model_rf(x_train: pd.DataFrame, y_train: pd.Series, mode: str) -> GridSearchCV:
    ...
```

- Expliciter au maximum les types d'entr√©e et de sortie des fonctions.
- On peut parler de **documentation implicite** $\Rightarrow$ on cherche √† √©viter √† un utilisateur d'utiliser des objets incompatibles avec ce qui a √©t√© √©tabli.

:::{.callout-note}

`mypy` va nous permettre d'effectuer ce contr√¥le *(static type checking)*, c'est √† dire de v√©rifier si les valeurs assign√©es aux variables, les arguments pass√©s aux fonctions et les valeurs de retour correspondent aux types attendus.

:::

## Docstrings {.smaller}

- Chaque fonction √† interface publique poss√®de une docstring structur√©e :
    - Nom de la fonction et description succinte
    - Param√®tre(s) d'entr√©e et param√®tre(s) de sortie  
    - Lev√©e d'exception (si il y en a)
    - Au minimum un exemple d'utilisation

*Exemple* avec la fonction `model_rf` du module `models.py` : 

```python
"""`model_rf`: Effectue une recherche exhaustive (Cross-Validation) des meilleurs param√®tres
    en utilisant une Random Forest. Les param√®tres optimis√©s sont :

    - n_estimators
    - max_depth

    ---------
    `Parameters`
    --------- ::

        x_train (pd.DataFrame): # L'ensemble d'entrainement
        y_train (pd.Series): # La variable √† pr√©dire
        mode (str): # regression | classification

    `Raises`
    --------- ::

        ValueError: # Une erreur est lev√©e quand le mode est invalide

    `Returns`
    --------- ::

        GridSearchCV

    `Example(s)`
    ---------

    >>> model_rf(x_train=X_train, y_train=y_train, mode = "regression")
    ... Entrainement du mod√®le : Random Forest
    ... GridSearchCV(estimator=Pipeline(steps=[('imputation', SimpleImputer()),
    ...                                   ('echelle', MinMaxScaler()),
    ...                                   ('entrainement',
    ...                                    RandomForestRegressor())]),
    ...         n_jobs=-1,
    ...         param_grid={'entrainement__max_depth': range(1, 10),
    ...                     'entrainement__n_estimators': range(10, 50, 10),
    ...                     'imputation__strategy': ['mean', 'median',
    ...                                              'most_frequent']},
    ...         return_train_score=True)
    """
```

::: {.notes}
- Un vrai petit tutoriel pour chaque fonction
- Description 
- Param√®tres
- Raises en cas de potentiel erreur
- Return
- Exemple d'utilisation

Mais bon c'est bien beau ces lignes de description, pourrais-tu √™tre un peu plus po√©tique ?
:::

## üßô‚Äç‚ôÇÔ∏è Poetry {.smaller}

**Gestion des d√©pendances** : `poetry` simplifie la gestion des d√©pendances en utilisant un fichier de configuration pyproject.toml. Il permet de sp√©cifier les d√©pendances directes et les d√©pendances de d√©veloppement requises pour le projet.

**Environnement Virtuel** : venv isol√© pour le projet, aidant √† maintenir un environnement de d√©veloppement propre et √©vitant les conflits entre les versions des packages.

**Installation de d√©pendances** : Facilite l'installation des d√©pendances d√©finies dans le fichier de configuration en utilisant la commande `poetry install`.

```powershell
py -m poetry install
```

::: {.notes}
Eh bien Guillaume, avec `poetry` on va faire rimer nos d√©pendances !

Rapidement, on a d√©cid√© d'opter pour `poetry` car le moment fatidique ou un d'entre nous d√©cide d'installer localemet un package et que l'autre ne l'a pas arrivait un peu trop souvent et √ßa c'√©tait pas super po√©tique justement.
:::


## üö¢ Modulaire !{.smaller}

S√©paration des composants du projet :

```
‚îú‚îÄ‚îÄ‚îÄdata
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüç∑vins.json
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüíæwine_links.csv
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄtables
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄüíæpred_classification.csv
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄüíæpred_regression.csv
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄüíæresult_ml_classification.csv
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄüíæresult_ml_regression.csv
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄüíæimportance.csv
‚îú‚îÄ‚îÄ‚îÄsrc
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄüì¶modules
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄ‚öôapp
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçst_functions.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçst_plots.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçst_selectors.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçst_tables.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄüêçst_tables.py
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄ‚öôml_models
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçimportance_script.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçmodels.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçoptimisation_script.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçprediction_script.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄüêçprediction.py
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄ‚öôscraping
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçmystical_soup.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçpage_scraper.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçscraping_functions.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄüêçvin_dataclass.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄüêçwine_scraper.py
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄüêçml_trigger.py
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄüêçscraping_trigger.py
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄüêçbear_cleaner.py
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄüêçutils.py
‚îú‚îÄ‚îÄ‚îÄüê≥Dockerfile
‚îú‚îÄ‚îÄ‚îÄüßô‚Äç‚ôÇÔ∏èpoetry.lock
‚îú‚îÄ‚îÄ‚îÄüìçpyproject.toml
‚îú‚îÄ‚îÄ‚îÄüìòREADME.md
‚îî‚îÄ‚îÄ‚îÄüêçstreamlit_app.py
```

::: {.notes}
- Le projet commen√ßant a √™tre bien fourni, n√©c√©ssit√© de modulariser le tout pour apporter un peu de clart√© pour le d√©veloppeur.
:::

## üê≥ Docker, Partie I {.smaller}

**Pourquoi utiliser Docker ?**

**Isolation** : Docker permet d'isoler l'application, ses d√©pendances et son environnement d'ex√©cution dans un conteneur. Cela signifie que l'application s'ex√©cute avec ses propres ressources et d√©pendances sans affecter l'environnement h√¥te.

**Portabilit√©** : Une fois que l'image Docker est cr√©√©e, elle peut √™tre ex√©cut√©e sur n'importe quel syst√®me prenant en charge Docker, offrant une portabilit√© √©lev√©e.

<hr>

**Comment ?** $\Rightarrow$ `Dockerfile`

Docker assure la reproductibilit√© en permettant √† n'importe qui de construire et d'ex√©cuter le **m√™me conteneur** √† partir des sp√©cifications d√©finies dans le `Dockerfile`.

:::{.notes}
Le `Dockerfile` sp√©cifie les √©tapes pour installer les d√©pendances de l'application (dans ce cas, on va utiliser `poetry` pour g√©rer les d√©pendances) et configurer un environnement minimaliste √† l'int√©rieur du conteneur.
:::

## üê≥ Docker, Partie II {.smaller}

- *Contenu du `Dockerfile` :*

```{.Dockerfile code-line-numbers="|1|2|4|6-8|10-13|15-16|18|20|22|24|"}
FROM python:3.10-slim-buster
WORKDIR /app

COPY pyproject.toml poetry.lock ./

RUN pip install poetry \ 
    && poetry config virtualenvs.create false \
    && poetry install --no-dev --no-interaction --no-ansi

COPY streamlit_app.py .
COPY src ./src
COPY data ./data
COPY img ./img

RUN addgroup --system app \
    && adduser --system --group app

USER app

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

ENTRYPOINT ["python", "-m", "streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

:::{.notes}
Regardons plus en d√©tail ce que contient ce `Dockerfile`. 

FROM python:3.10-slim-buster

1. **FROM python:3.10-slim-buster** $\Rightarrow$ sp√©cifie l'image de base √† partir de laquelle notre image Docker sera construite. On utilise l'image Python *3.10-slim-buster* comme base. Cette image *slim-buster* est une version r√©duite plus rapide de l'image compl√®te avec le minimum de d√©pendances possible.
2. **WORKDIR /app** $\Rightarrow$ d√©finit le r√©pertoire de travail dans le conteneur. Toutes les instructions suivantes sont ex√©cut√©es √† partir de ce r√©pertoire.
3. **COPY pyproject.toml poetry.lock ./** $\Rightarrow$ copie les fichiers pyproject.toml et poetry.lock depuis le r√©pertoire local dans le r√©pertoire *app* du conteneur.
4. **RUN pip install poetry && poetry config virtualenvs.create false && poetry install --no-dev --no-interaction --no-ansi** $\Rightarrow$ Ex√©cute plusieurs commandes en une seule instruction RUN :
    - On installe `poetry` dans le conteneur via pip.
    - On configure `poetry` pour ne pas cr√©er d'environnement virtuel.
    - On Installe les d√©pendances du projet √† partir de poetry.lock, en excluant les d√©pendances de d√©veloppement (--no-dev), sans interaction (--no-interaction) et sans afficher de couleurs ANSI (--no-ansi). En effet, on ne copie pas nos tests dans le conteneur, √ßa alourdirait l'image pour rien.
5. **COPY streamlit_app.py** $\Rightarrow$ On copie le fichier `streamlit_app.py`, le dossier `src`, `data` et `img` depuis le r√©pertoire local dans le r√©pertoire *app* du conteneur.
6. **RUN addgroup --system app && adduser --system --group app** $\Rightarrow$ Cr√©e un groupe syst√®me appel√© app et un utilisateur syst√®me √©galement appel√© app - **On veut ABSOLUMENT √©viter d'utiliser l'utilisateur root donc c'est pas pour √ßa qu'on configure un utilisateur**
7. **USER app** $\Rightarrow$ D√©finit l'utilisateur qui ex√©cutera les commandes suivantes dans le conteneur comme √©tant l'utilisateur **app**.
8. **EXPOSE 8501** $\Rightarrow$ Expose le port 8501. Indique simplement quel port qui doit √™tre publi√© lors de l'ex√©cution de l'image.
9. **HEALTHCHECK** $\Rightarrow$ Pour tester si le conteneur fonctionne toujours correctement.
10. **ENTRYPOINT** $\Rightarrow$ D√©finit la commande d'entr√©e √† ex√©cuter quand le conteneur bas√© sur l'image est d√©marr√©. Dans notre cas, on fait un streamlit run de notre application sur le port 8501.
:::

## üèóÔ∏è Le conteneur en action ! {.smaller}

Il faut tout d'abord s'assurer d'avoir t√©l√©charg√© **Docker Desktop** avant toute chose.

Une fois install√©, l'image est construite en ex√©cutant la commande suivante dans un terminal :

```powershell
docker image build . -t "wine_scraping"
```

Une fois la cr√©ation de l'image termin√©e, on peut consulter la taille de celle-ci avec :

```powershell
docker images
```

Ensuite, pour lancer le conteneur Docker avec l'utilisateur *app* sur le port initial (8501) de `streamlit`, il suffit de faire :

```powershell
docker run -u app -p 8501:8501 wine_scraping
```

üéâ Une fois le conteneur lanc√©, on le voit apparaitre dans **Docker Desktop**. Pour acc√©der √† l'application, il faut se rendre sur [*http://localhost:8501/*](http://localhost:8501/).

## Fin {.smaller background-image="img\weird_man.png" background-opacity="0.25"}

> On ne sait pas pourquoi on a fait tout √ßa, car nous voulions simplement trouver une bouteille pour f√™ter notre anniversaire, et on se retrouve avec une application d'analyse de donn√©es qui ne nous aide en aucun cas √† trouver notre breuvage...üòµ

## R√©f√©rences

- Images : **DALL-E**
